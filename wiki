#!/usr/bin/env python
import sys
import argparse
import urllib2
from urllib import quote
import re
import json

def wiki(searchterm):
    """return the top wiki search result for the term"""
    searchterm = quote(searchterm)

    # TODO: internationalize.
    url = "https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={0}&format=json"
    url = url.format(searchterm)

    result = json.loads(urllib2.urlopen(url).read())

    pages = result["query"]["search"]

    # try to reject disambiguation pages
    pages = [p for p in pages if not 'may refer to' in p["snippet"]]

    if not pages:
        return

    return pages[0]

def fulltext(pagetitle):
    page = quote(pagetitle.encode("utf8"))
    url = "http://en.wikipedia.org/w/api.php?format=json&action=parse&page=#{0}"
    url = url.format(page)

    result = json.loads(urllib2.urlopen(url).read())

    pages = result["parse"]["text"]

def main(args):
    wikipage = wiki(' '.join(args.searchterm))

    # urlquote requires non-unicode strings... ugh
    if args.snippet:

    else:
        page = quote(wikipage["title"].encode("utf8"))
        print "http://en.wikipedia.org/wiki/{0}".format(page)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Query wikipedia from the command line')
    parser.add_argument('searchterm', metavar='searchterm', type=str, nargs='+',
                       help='The term to search for. Any amount of words.')

    parser.add_argument('--snippet', dest='snippet', action='store_const',
                       const=True, default=False,
                       help='return a snippet of text instead of a URL')

    main(parser.parse_args())
